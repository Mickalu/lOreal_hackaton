{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Unnamed: 0                                               text  \\\n",
       "0               0  Skeeterbytes wrote: Bassam Guy wrote: I don't ...   \n",
       "1               1  Refueling before the long week üçµ - You‚Äôre mean...   \n",
       "2               2  Just in case no one has told you today YOU ARE...   \n",
       "3               3  Do not forget to get some sunshine safely if y...   \n",
       "4               4  Abstract Background Humans have dramatically c...   \n",
       "...           ...                                                ...   \n",
       "10567       13209  ‚òë Day: 273 Outifit: Thor (Gold Foil) Back Blin...   \n",
       "10568       13210  In order to study the various trends and patte...   \n",
       "10569       13212  This brand has not yet registered with Influen...   \n",
       "10570       13213  here is my regime get rid of any acne scars an...   \n",
       "10571       13214  It's true, I used to work as a caddie at Trump...   \n",
       "\n",
       "       skincare  hair  make-up  other  index  \n",
       "0           0.0   0.0      0.0    1.0      0  \n",
       "1           0.0   0.0      0.0    1.0      1  \n",
       "2           0.0   0.0      1.0    0.0      2  \n",
       "3           0.0   0.0      0.0    1.0      3  \n",
       "4           0.0   0.0      0.0    1.0      4  \n",
       "...         ...   ...      ...    ...    ...  \n",
       "10567       0.0   0.0      0.0    1.0  13209  \n",
       "10568       0.0   0.0      0.0    1.0  13210  \n",
       "10569       0.0   0.0      0.0    1.0  13212  \n",
       "10570       1.0   0.0      0.0    0.0  13213  \n",
       "10571       0.0   0.0      0.0    1.0  13214  \n",
       "\n",
       "[10572 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>skincare</th>\n      <th>hair</th>\n      <th>make-up</th>\n      <th>other</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Skeeterbytes wrote: Bassam Guy wrote: I don't ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Refueling before the long week üçµ - You‚Äôre mean...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Just in case no one has told you today YOU ARE...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Do not forget to get some sunshine safely if y...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Abstract Background Humans have dramatically c...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10567</th>\n      <td>13209</td>\n      <td>‚òë Day: 273 Outifit: Thor (Gold Foil) Back Blin...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13209</td>\n    </tr>\n    <tr>\n      <th>10568</th>\n      <td>13210</td>\n      <td>In order to study the various trends and patte...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13210</td>\n    </tr>\n    <tr>\n      <th>10569</th>\n      <td>13212</td>\n      <td>This brand has not yet registered with Influen...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13212</td>\n    </tr>\n    <tr>\n      <th>10570</th>\n      <td>13213</td>\n      <td>here is my regime get rid of any acne scars an...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13213</td>\n    </tr>\n    <tr>\n      <th>10571</th>\n      <td>13214</td>\n      <td>It's true, I used to work as a caddie at Trump...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13214</td>\n    </tr>\n  </tbody>\n</table>\n<p>10572 rows √ó 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/hackathon_loreal_train_set.csv\")\n",
    "df_train"
   ]
  },
  {
   "source": [
    "# watch data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'skincare', 'hair', 'make-up', 'other', 'index'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, text, skincare, hair, make-up, other, index]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>skincare</th>\n      <th>hair</th>\n      <th>make-up</th>\n      <th>other</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df = df_train[df_train['Unnamed: 0'] != df_train['index']]\n",
    "df"
   ]
  },
  {
   "source": [
    "# delete one columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    text  skincare  hair  \\\n",
       "0      Skeeterbytes wrote: Bassam Guy wrote: I don't ...       0.0   0.0   \n",
       "1      Refueling before the long week üçµ - You‚Äôre mean...       0.0   0.0   \n",
       "2      Just in case no one has told you today YOU ARE...       0.0   0.0   \n",
       "3      Do not forget to get some sunshine safely if y...       0.0   0.0   \n",
       "4      Abstract Background Humans have dramatically c...       0.0   0.0   \n",
       "...                                                  ...       ...   ...   \n",
       "10567  ‚òë Day: 273 Outifit: Thor (Gold Foil) Back Blin...       0.0   0.0   \n",
       "10568  In order to study the various trends and patte...       0.0   0.0   \n",
       "10569  This brand has not yet registered with Influen...       0.0   0.0   \n",
       "10570  here is my regime get rid of any acne scars an...       1.0   0.0   \n",
       "10571  It's true, I used to work as a caddie at Trump...       0.0   0.0   \n",
       "\n",
       "       make-up  other  index  \n",
       "0          0.0    1.0      0  \n",
       "1          0.0    1.0      1  \n",
       "2          1.0    0.0      2  \n",
       "3          0.0    1.0      3  \n",
       "4          0.0    1.0      4  \n",
       "...        ...    ...    ...  \n",
       "10567      0.0    1.0  13209  \n",
       "10568      0.0    1.0  13210  \n",
       "10569      0.0    1.0  13212  \n",
       "10570      0.0    0.0  13213  \n",
       "10571      0.0    1.0  13214  \n",
       "\n",
       "[10572 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>skincare</th>\n      <th>hair</th>\n      <th>make-up</th>\n      <th>other</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Skeeterbytes wrote: Bassam Guy wrote: I don't ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Refueling before the long week üçµ - You‚Äôre mean...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Just in case no one has told you today YOU ARE...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Do not forget to get some sunshine safely if y...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abstract Background Humans have dramatically c...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10567</th>\n      <td>‚òë Day: 273 Outifit: Thor (Gold Foil) Back Blin...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13209</td>\n    </tr>\n    <tr>\n      <th>10568</th>\n      <td>In order to study the various trends and patte...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13210</td>\n    </tr>\n    <tr>\n      <th>10569</th>\n      <td>This brand has not yet registered with Influen...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13212</td>\n    </tr>\n    <tr>\n      <th>10570</th>\n      <td>here is my regime get rid of any acne scars an...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13213</td>\n    </tr>\n    <tr>\n      <th>10571</th>\n      <td>It's true, I used to work as a caddie at Trump...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13214</td>\n    </tr>\n  </tbody>\n</table>\n<p>10572 rows √ó 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_train = df_train.drop(['Unnamed: 0'], axis = 1)\n",
    "df_train"
   ]
  },
  {
   "source": [
    "# preprocessing one text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from nltk import word_tokenize, WordNetLemmatizer, PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk import ngrams\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Refueling before the long week üçµ - You‚Äôre meant to Drink it, but I prefer it in my üçµ From to , matcha is a natural powder of freshly ground leaves! ‚úÖthanks to its numerous antioxidant benefits! ‚úÖIncluding it in your beauty routine requires very little time and effort to see benefits ‚úÖ The best part of it is that it‚Äôs already in your cupboard and doubles as a delicious drink? It really doesn‚Äôt get better than this! üõí Matcha tea purchased from my favorite online store faithfultonature'"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "Onetext = df_train['text'].iloc[1]\n",
    "Onetext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emoji.unicode_codes import UNICODE_EMOJI\n",
    "import regex\n",
    "\n",
    "def extract_emojis(s):\n",
    "  for c in s:\n",
    "    if c in UNICODE_EMOJI:\n",
    "        print(True)\n",
    "extract_emojis(Onetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'refueling before the long week üçµ - you‚Äôre meant to drink it, but i prefer it in my üçµ from to , matcha is a natural powder of freshly ground leaves! ‚úÖthanks to its numerous antioxidant benefits! ‚úÖincluding it in your beauty routine requires very little time and effort to see benefits ‚úÖ the best part of it is that it‚Äôs already in your cupboard and doubles as a delicious drink? it really doesn‚Äôt get better than this! üõí matcha tea purchased from my favorite online store faithfultonature'"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "OnetextLower = Onetext.lower()\n",
    "OnetextLower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['refueling',\n",
       " 'before',\n",
       " 'the',\n",
       " 'long',\n",
       " 'week',\n",
       " 'üçµ',\n",
       " '-',\n",
       " 'you',\n",
       " '‚Äô',\n",
       " 're',\n",
       " 'meant',\n",
       " 'to',\n",
       " 'drink',\n",
       " 'it',\n",
       " ',',\n",
       " 'but',\n",
       " 'i',\n",
       " 'prefer',\n",
       " 'it',\n",
       " 'in',\n",
       " 'my',\n",
       " 'üçµ',\n",
       " 'from',\n",
       " 'to',\n",
       " ',',\n",
       " 'matcha',\n",
       " 'is',\n",
       " 'a',\n",
       " 'natural',\n",
       " 'powder',\n",
       " 'of',\n",
       " 'freshly',\n",
       " 'ground',\n",
       " 'leaves',\n",
       " '!',\n",
       " '‚úÖthanks',\n",
       " 'to',\n",
       " 'its',\n",
       " 'numerous',\n",
       " 'antioxidant',\n",
       " 'benefits',\n",
       " '!',\n",
       " '‚úÖincluding',\n",
       " 'it',\n",
       " 'in',\n",
       " 'your',\n",
       " 'beauty',\n",
       " 'routine',\n",
       " 'requires',\n",
       " 'very',\n",
       " 'little',\n",
       " 'time',\n",
       " 'and',\n",
       " 'effort',\n",
       " 'to',\n",
       " 'see',\n",
       " 'benefits',\n",
       " '‚úÖ',\n",
       " 'the',\n",
       " 'best',\n",
       " 'part',\n",
       " 'of',\n",
       " 'it',\n",
       " 'is',\n",
       " 'that',\n",
       " 'it',\n",
       " '‚Äô',\n",
       " 's',\n",
       " 'already',\n",
       " 'in',\n",
       " 'your',\n",
       " 'cupboard',\n",
       " 'and',\n",
       " 'doubles',\n",
       " 'as',\n",
       " 'a',\n",
       " 'delicious',\n",
       " 'drink',\n",
       " '?',\n",
       " 'it',\n",
       " 'really',\n",
       " 'doesn',\n",
       " '‚Äô',\n",
       " 't',\n",
       " 'get',\n",
       " 'better',\n",
       " 'than',\n",
       " 'this',\n",
       " '!',\n",
       " 'üõí',\n",
       " 'matcha',\n",
       " 'tea',\n",
       " 'purchased',\n",
       " 'from',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'online',\n",
       " 'store',\n",
       " 'faithfultonature']"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "tokenizeSingletext = word_tokenize(OnetextLower)\n",
    "tokenizeSingletext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['refueling',\n",
       " 'before',\n",
       " 'the',\n",
       " 'long',\n",
       " 'week',\n",
       " 'üçµ',\n",
       " '-',\n",
       " 'you',\n",
       " '‚Äô',\n",
       " 're',\n",
       " 'meant',\n",
       " 'to',\n",
       " 'drink',\n",
       " 'it',\n",
       " ',',\n",
       " 'but',\n",
       " 'i',\n",
       " 'prefer',\n",
       " 'it',\n",
       " 'in',\n",
       " 'my',\n",
       " 'üçµ',\n",
       " 'from',\n",
       " 'to',\n",
       " ',',\n",
       " 'matcha',\n",
       " 'is',\n",
       " 'a',\n",
       " 'natural',\n",
       " 'powder',\n",
       " 'of',\n",
       " 'freshly',\n",
       " 'ground',\n",
       " 'leaf',\n",
       " '!',\n",
       " '‚úÖthanks',\n",
       " 'to',\n",
       " 'it',\n",
       " 'numerous',\n",
       " 'antioxidant',\n",
       " 'benefit',\n",
       " '!',\n",
       " '‚úÖincluding',\n",
       " 'it',\n",
       " 'in',\n",
       " 'your',\n",
       " 'beauty',\n",
       " 'routine',\n",
       " 'requires',\n",
       " 'very',\n",
       " 'little',\n",
       " 'time',\n",
       " 'and',\n",
       " 'effort',\n",
       " 'to',\n",
       " 'see',\n",
       " 'benefit',\n",
       " '‚úÖ',\n",
       " 'the',\n",
       " 'best',\n",
       " 'part',\n",
       " 'of',\n",
       " 'it',\n",
       " 'is',\n",
       " 'that',\n",
       " 'it',\n",
       " '‚Äô',\n",
       " 's',\n",
       " 'already',\n",
       " 'in',\n",
       " 'your',\n",
       " 'cupboard',\n",
       " 'and',\n",
       " 'double',\n",
       " 'a',\n",
       " 'a',\n",
       " 'delicious',\n",
       " 'drink',\n",
       " '?',\n",
       " 'it',\n",
       " 'really',\n",
       " 'doesn',\n",
       " '‚Äô',\n",
       " 't',\n",
       " 'get',\n",
       " 'better',\n",
       " 'than',\n",
       " 'this',\n",
       " '!',\n",
       " 'üõí',\n",
       " 'matcha',\n",
       " 'tea',\n",
       " 'purchased',\n",
       " 'from',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'online',\n",
       " 'store',\n",
       " 'faithfultonature']"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizeSingleText = list(map(lemmatizer.lemmatize, tokenizeSingletext))\n",
    "lemmatizeSingleText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['refueling',\n",
       " 'before',\n",
       " 'the',\n",
       " 'long',\n",
       " 'week',\n",
       " 'you',\n",
       " '‚Äô',\n",
       " 're',\n",
       " 'meant',\n",
       " 'to',\n",
       " 'drink',\n",
       " 'it',\n",
       " 'but',\n",
       " 'i',\n",
       " 'prefer',\n",
       " 'it',\n",
       " 'in',\n",
       " 'my',\n",
       " 'from',\n",
       " 'to',\n",
       " 'matcha',\n",
       " 'is',\n",
       " 'a',\n",
       " 'natural',\n",
       " 'powder',\n",
       " 'of',\n",
       " 'freshly',\n",
       " 'ground',\n",
       " 'leaf',\n",
       " '‚úÖthanks',\n",
       " 'to',\n",
       " 'it',\n",
       " 'numerous',\n",
       " 'antioxidant',\n",
       " 'benefit',\n",
       " '‚úÖincluding',\n",
       " 'it',\n",
       " 'in',\n",
       " 'your',\n",
       " 'beauty',\n",
       " 'routine',\n",
       " 'requires',\n",
       " 'very',\n",
       " 'little',\n",
       " 'time',\n",
       " 'and',\n",
       " 'effort',\n",
       " 'to',\n",
       " 'see',\n",
       " 'benefit',\n",
       " '‚úÖ',\n",
       " 'the',\n",
       " 'best',\n",
       " 'part',\n",
       " 'of',\n",
       " 'it',\n",
       " 'is',\n",
       " 'that',\n",
       " 'it',\n",
       " '‚Äô',\n",
       " 's',\n",
       " 'already',\n",
       " 'in',\n",
       " 'your',\n",
       " 'cupboard',\n",
       " 'and',\n",
       " 'double',\n",
       " 'a',\n",
       " 'a',\n",
       " 'delicious',\n",
       " 'drink',\n",
       " 'it',\n",
       " 'really',\n",
       " 'doesn',\n",
       " '‚Äô',\n",
       " 't',\n",
       " 'get',\n",
       " 'better',\n",
       " 'than',\n",
       " 'this',\n",
       " 'üõí',\n",
       " 'matcha',\n",
       " 'tea',\n",
       " 'purchased',\n",
       " 'from',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'online',\n",
       " 'store',\n",
       " 'faithfultonature']"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "stop_punctuation = [':', '(', ')', '/', '|', ',', ']', ';',\n",
    "                    '.', '*', '#', '\"', '&', '~', '``',\n",
    "                    '-', '_', '\\\\', '@','?','!','\\'', '[', 'üçµ']\n",
    "TextCleanPonctuation = [word for word in lemmatizeSingleText if word not in stop_punctuation]\n",
    "TextCleanPonctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['refueling',\n",
       " 'long',\n",
       " 'week',\n",
       " 'üçµ',\n",
       " '‚Äô',\n",
       " 'meant',\n",
       " 'drink',\n",
       " 'prefer',\n",
       " 'üçµ',\n",
       " 'matcha',\n",
       " 'natural',\n",
       " 'powder',\n",
       " 'freshly',\n",
       " 'ground',\n",
       " 'leaf',\n",
       " '‚úÖthanks',\n",
       " 'numerous',\n",
       " 'antioxidant',\n",
       " 'benefit',\n",
       " '‚úÖincluding',\n",
       " 'beauty',\n",
       " 'routine',\n",
       " 'requires',\n",
       " 'little',\n",
       " 'time',\n",
       " 'effort',\n",
       " 'see',\n",
       " 'benefit',\n",
       " '‚úÖ',\n",
       " 'best',\n",
       " 'part',\n",
       " '‚Äô',\n",
       " 'already',\n",
       " 'cupboard',\n",
       " 'double',\n",
       " 'delicious',\n",
       " 'drink',\n",
       " 'really',\n",
       " '‚Äô',\n",
       " 'get',\n",
       " 'better',\n",
       " 'üõí',\n",
       " 'matcha',\n",
       " 'tea',\n",
       " 'purchased',\n",
       " 'favorite',\n",
       " 'online',\n",
       " 'store',\n",
       " 'faithfultonature']"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "stoplist = stopwords.words('english')\n",
    "TextCleanPonctuationWord = [word for word in TextCleanPonctuation if word not in stoplist]\n",
    "TextCleanPonctuationWord"
   ]
  },
  {
   "source": [
    "# functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(singleText):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_punctuation = [':', '(', ')', '/', '|', ',', ']', ';',\n",
    "                    '.', '*', '#', '\"', '&', '~', '``',\n",
    "                    '-', '_', '\\\\', '@','?','!','\\'', '[']\n",
    "    stoplist = stopwords.words('english')\n",
    "\n",
    "    LowerSingleText = singleText.lower()\n",
    "    tokenizeSingletext = word_tokenize(LowerSingleText)\n",
    "    lemmatizeSingleText = list(map(lemmatizer.lemmatize, tokenizeSingletext))\n",
    "    \n",
    "    TextCleanPonctuation = [word for word in lemmatizeSingleText if word not in stop_punctuation and word not in stoplist]\n",
    "\n",
    "    return TextCleanPonctuation\n",
    "\n",
    "def clean_text(text):\n",
    "    text_preprocessed = preprocessing(text)\n",
    "    \n",
    "    clean_mail = [word for word in text_preprocessed if word not in stop_punctuation and not word in stoplist]\n",
    "    return ' '.join(clean_mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"skeeterbytes wrote bassam guy wrote n't anything longer 60mm except $ 99 plastic fantastic '' 40-150. 've never really tried avian photography would like get decent shot unlike opportunity arises used c-af+tr retrospect since turkey lawyer refused fly despite plea would s-af done better mf peaking magnify exposed lawyer dressed dark suit bright cloudy sky meteorologist say smoke remnant ca northern va wa +2 +2.5 ev much encouraged chroma 'm great judging distance would say wa 35+ meter away pretty intense purple fringing lightroom ha effective one-click remover 'm sure software ha hard control know panasonic 7-14 4 never use c-af+tr preferring standard c-af s-af instance s-af fine attorney n't going anywhere pay bill get s-af+magnify allow tweak focus plus want stop lens bit sharpen except 7-14 nothing else f2.8 5.6 seems stopped 'll watch tried magnify wa shaky long fl 'll try lower scale factor also raise shutter speed freeze flapping 're iso200 's good lens within realm 40-150 pro league better 10x price birding test petapixel fstoppers rated e-m5 iii pretty well c-af+tr n't use often location 5 minute walk home perhaps 'll try keep experimenting rick thanks helpful reply\""
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "result = clean_text(df_train[\"text\"].iloc[0])\n",
    "result"
   ]
  },
  {
   "source": [
    "# On applique cela pour toute la base de donn√©e"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        skeeterbytes wrote bassam guy wrote n't anythi...\n",
       "1        refueling long week üçµ ‚Äô meant drink prefer üçµ m...\n",
       "2        case one ha told today strong beautiful love üåπ...\n",
       "3        forget get sunshine safely ‚òÄÔ∏è head link bio se...\n",
       "4        abstract background human dramatically changed...\n",
       "                               ...                        \n",
       "10567    ‚òë day 273 outifit thor gold foil back bling et...\n",
       "10568    order study various trend pattern prevailing c...\n",
       "10569    brand ha yet registered influenster work brand...\n",
       "10570    regime get rid acne scar get way smoother heal...\n",
       "10571    's true used work caddie trump national nj don...\n",
       "Name: clean_content, Length: 10572, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "df_train[\"clean_content\"] = df_train.text.apply(clean_text)\n",
    "df_train[\"clean_content\"]"
   ]
  },
  {
   "source": [
    "# vectorization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "## separate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        skeeterbytes wrote bassam guy wrote n't anythi...\n",
       "1        refueling long week üçµ ‚Äô meant drink prefer üçµ m...\n",
       "2        case one ha told today strong beautiful love üåπ...\n",
       "3        forget get sunshine safely ‚òÄÔ∏è head link bio se...\n",
       "4        abstract background human dramatically changed...\n",
       "                               ...                        \n",
       "10567    ‚òë day 273 outifit thor gold foil back bling et...\n",
       "10568    order study various trend pattern prevailing c...\n",
       "10569    brand ha yet registered influenster work brand...\n",
       "10570    regime get rid acne scar get way smoother heal...\n",
       "10571    's true used work caddie trump national nj don...\n",
       "Name: clean_content, Length: 10572, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "X = df_train_clean['clean_content']\n",
    "Y = df_train_clean.drop(['clean_content', 'index'], axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<1x71330 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 71 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
    "pipe.fit(x_train)\n",
    "feat_train = pipe.transform(x_train)\n",
    "feat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<8457x71330 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 704785 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "feat_train"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=50)"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(feat_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "feat_test = pipe.transform(x_test)\n",
    "clf.score(feat_test, y_test) "
   ]
  },
  {
   "source": [
    "# visualisation result"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([[1.  , 0.  ],\n",
       "        [0.96, 0.04],\n",
       "        [0.98, 0.02],\n",
       "        ...,\n",
       "        [0.9 , 0.1 ],\n",
       "        [0.92, 0.08],\n",
       "        [1.  , 0.  ]]),\n",
       " array([[0.98      , 0.02      ],\n",
       "        [0.76666667, 0.23333333],\n",
       "        [1.        , 0.        ],\n",
       "        ...,\n",
       "        [0.92      , 0.08      ],\n",
       "        [0.975     , 0.025     ],\n",
       "        [0.97      , 0.03      ]]),\n",
       " array([[0.96, 0.04],\n",
       "        [0.86, 0.14],\n",
       "        [0.96, 0.04],\n",
       "        ...,\n",
       "        [0.94, 0.06],\n",
       "        [0.98, 0.02],\n",
       "        [1.  , 0.  ]]),\n",
       " array([[0.06      , 0.94      ],\n",
       "        [0.39333333, 0.60666667],\n",
       "        [0.06      , 0.94      ],\n",
       "        ...,\n",
       "        [0.24      , 0.76      ],\n",
       "        [0.105     , 0.895     ],\n",
       "        [0.03      , 0.97      ]])]"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "score = clf.predict_proba(feat_test)\n",
    "score\n",
    "#fpr, tpr, th = roc_curve(y_list_test, score[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'fpr' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-ecdce8a2602c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'k--'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0maucf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auc=%1.5f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0maucf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Courbe ROC - classifieur de sentiments'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fpr' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "aucf = auc(fpr, tpr)\n",
    "ax.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
    "ax.set_title('Courbe ROC - classifieur de sentiments')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}