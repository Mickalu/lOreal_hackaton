{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from nltk import word_tokenize, WordNetLemmatizer, PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk import ngrams\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Unnamed: 0                                               text  \\\n",
       "0               0  Skeeterbytes wrote: Bassam Guy wrote: I don't ...   \n",
       "1               1  Refueling before the long week üçµ - You‚Äôre mean...   \n",
       "2               2  Just in case no one has told you today YOU ARE...   \n",
       "3               3  Do not forget to get some sunshine safely if y...   \n",
       "4               4  Abstract Background Humans have dramatically c...   \n",
       "...           ...                                                ...   \n",
       "10567       13209  ‚òë Day: 273 Outifit: Thor (Gold Foil) Back Blin...   \n",
       "10568       13210  In order to study the various trends and patte...   \n",
       "10569       13212  This brand has not yet registered with Influen...   \n",
       "10570       13213  here is my regime get rid of any acne scars an...   \n",
       "10571       13214  It's true, I used to work as a caddie at Trump...   \n",
       "\n",
       "       skincare  hair  make-up  other  index  \n",
       "0           0.0   0.0      0.0    1.0      0  \n",
       "1           0.0   0.0      0.0    1.0      1  \n",
       "2           0.0   0.0      1.0    0.0      2  \n",
       "3           0.0   0.0      0.0    1.0      3  \n",
       "4           0.0   0.0      0.0    1.0      4  \n",
       "...         ...   ...      ...    ...    ...  \n",
       "10567       0.0   0.0      0.0    1.0  13209  \n",
       "10568       0.0   0.0      0.0    1.0  13210  \n",
       "10569       0.0   0.0      0.0    1.0  13212  \n",
       "10570       1.0   0.0      0.0    0.0  13213  \n",
       "10571       0.0   0.0      0.0    1.0  13214  \n",
       "\n",
       "[10572 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>skincare</th>\n      <th>hair</th>\n      <th>make-up</th>\n      <th>other</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Skeeterbytes wrote: Bassam Guy wrote: I don't ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Refueling before the long week üçµ - You‚Äôre mean...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Just in case no one has told you today YOU ARE...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Do not forget to get some sunshine safely if y...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Abstract Background Humans have dramatically c...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10567</th>\n      <td>13209</td>\n      <td>‚òë Day: 273 Outifit: Thor (Gold Foil) Back Blin...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13209</td>\n    </tr>\n    <tr>\n      <th>10568</th>\n      <td>13210</td>\n      <td>In order to study the various trends and patte...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13210</td>\n    </tr>\n    <tr>\n      <th>10569</th>\n      <td>13212</td>\n      <td>This brand has not yet registered with Influen...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13212</td>\n    </tr>\n    <tr>\n      <th>10570</th>\n      <td>13213</td>\n      <td>here is my regime get rid of any acne scars an...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13213</td>\n    </tr>\n    <tr>\n      <th>10571</th>\n      <td>13214</td>\n      <td>It's true, I used to work as a caddie at Trump...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13214</td>\n    </tr>\n  </tbody>\n</table>\n<p>10572 rows √ó 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/hackathon_loreal_train_set.csv\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# watch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'skincare', 'hair', 'make-up', 'other', 'index'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, text, skincare, hair, make-up, other, index]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>skincare</th>\n      <th>hair</th>\n      <th>make-up</th>\n      <th>other</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df = df_train[df_train['Unnamed: 0'] != df_train['index']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# delete one columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    text  skincare  hair  \\\n",
       "0      Skeeterbytes wrote: Bassam Guy wrote: I don't ...       0.0   0.0   \n",
       "1      Refueling before the long week üçµ - You‚Äôre mean...       0.0   0.0   \n",
       "2      Just in case no one has told you today YOU ARE...       0.0   0.0   \n",
       "3      Do not forget to get some sunshine safely if y...       0.0   0.0   \n",
       "4      Abstract Background Humans have dramatically c...       0.0   0.0   \n",
       "...                                                  ...       ...   ...   \n",
       "10567  ‚òë Day: 273 Outifit: Thor (Gold Foil) Back Blin...       0.0   0.0   \n",
       "10568  In order to study the various trends and patte...       0.0   0.0   \n",
       "10569  This brand has not yet registered with Influen...       0.0   0.0   \n",
       "10570  here is my regime get rid of any acne scars an...       1.0   0.0   \n",
       "10571  It's true, I used to work as a caddie at Trump...       0.0   0.0   \n",
       "\n",
       "       make-up  other  index  \n",
       "0          0.0    1.0      0  \n",
       "1          0.0    1.0      1  \n",
       "2          1.0    0.0      2  \n",
       "3          0.0    1.0      3  \n",
       "4          0.0    1.0      4  \n",
       "...        ...    ...    ...  \n",
       "10567      0.0    1.0  13209  \n",
       "10568      0.0    1.0  13210  \n",
       "10569      0.0    1.0  13212  \n",
       "10570      0.0    0.0  13213  \n",
       "10571      0.0    1.0  13214  \n",
       "\n",
       "[10572 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>skincare</th>\n      <th>hair</th>\n      <th>make-up</th>\n      <th>other</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Skeeterbytes wrote: Bassam Guy wrote: I don't ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Refueling before the long week üçµ - You‚Äôre mean...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Just in case no one has told you today YOU ARE...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Do not forget to get some sunshine safely if y...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abstract Background Humans have dramatically c...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10567</th>\n      <td>‚òë Day: 273 Outifit: Thor (Gold Foil) Back Blin...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13209</td>\n    </tr>\n    <tr>\n      <th>10568</th>\n      <td>In order to study the various trends and patte...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13210</td>\n    </tr>\n    <tr>\n      <th>10569</th>\n      <td>This brand has not yet registered with Influen...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13212</td>\n    </tr>\n    <tr>\n      <th>10570</th>\n      <td>here is my regime get rid of any acne scars an...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13213</td>\n    </tr>\n    <tr>\n      <th>10571</th>\n      <td>It's true, I used to work as a caddie at Trump...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13214</td>\n    </tr>\n  </tbody>\n</table>\n<p>10572 rows √ó 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df_train = df_train.drop(['Unnamed: 0'], axis = 1)\n",
    "df_train"
   ]
  },
  {
   "source": [
    "## see disparite"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "skincare  :  1303\nhair  :  1272\nmake-up  :  1907\nother  :  6667\n"
     ]
    }
   ],
   "source": [
    "array_col = ['skincare', 'hair', 'make-up', 'other']\n",
    "\n",
    "for val in array_col:\n",
    "    len_result = len(df_train[df_train[val] == 1])\n",
    "    print(val, \" : \" ,len_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing one text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from nltk import word_tokenize, WordNetLemmatizer, PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk import ngrams\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Just in case no one has told you today YOU ARE STRONG BEAUTIFUL I LOVE YOU üåπ Por si no te lo han dicho hoy TU ERES FUERTE BONITA Y TE AMO üåπ Wicked Gel Liner coupon code BIRDY Hydrating spray code BIRDY pearl radiance primer foundation in almond shape tape contour concealer hoola contour stick bronzer powder translucent powder rose gold highlight code BIRDY whirl lip liner Nude potion BIRDY'"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "Onetext = df_train['text'].iloc[2]\n",
    "Onetext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to remove emoji.\n",
    "def emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "                           \n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Just in case no one has told you today YOU ARE STRONG BEAUTIFUL I LOVE YOU  Por si no te lo han dicho hoy TU ERES FUERTE BONITA Y TE AMO  Wicked Gel Liner coupon code BIRDY Hydrating spray code BIRDY pearl radiance primer foundation in almond shape tape contour concealer hoola contour stick bronzer powder translucent powder rose gold highlight code BIRDY whirl lip liner Nude potion BIRDY'"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "emoji(Onetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "OnetextLower = Onetext.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizeSingletext = word_tokenize(OnetextLower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n2\n4\n2\n3\n3\n4\n3\n5\n3\n3\n6\n9\n1\n4\n3\n1\n3\n2\n2\n2\n2\n3\n5\n3\n2\n4\n6\n6\n1\n2\n3\n1\n6\n3\n5\n6\n4\n5\n9\n5\n4\n5\n5\n8\n6\n10\n2\n6\n5\n4\n7\n9\n5\n7\n5\n7\n6\n11\n6\n4\n4\n9\n4\n5\n5\n3\n5\n4\n6\n5\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "#def del_alone(word):\n",
    "#    print(len(word))\n",
    "#suppAlone = list(map(del_alone, tokenizeSingletext))\n",
    "#suppAlone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizeSingleText = list(map(lemmatizer.lemmatize, tokenizeSingletext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_punctuation = [':', '(', ')', '/', '|', ',', ']', ';',\n",
    "                    '.', '*', '#', '\"', '&', '~', '``',\n",
    "                    '-', '_', '\\\\', '@','?','!','\\'', '[', '<', '>', \"‚Äô\"]\n",
    "TextCleanPonctuation = [word for word in lemmatizeSingleText if word not in stop_punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english')\n",
    "TextCleanPonctuationWord = [word for word in TextCleanPonctuation if word not in stoplist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('case', 'NN'),\n",
       " ('one', 'CD'),\n",
       " ('ha', 'NN'),\n",
       " ('told', 'VBD'),\n",
       " ('today', 'NN'),\n",
       " ('strong', 'JJ'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('love', 'NN'),\n",
       " ('üåπ', 'NNP'),\n",
       " ('por', 'NN'),\n",
       " ('si', 'NN'),\n",
       " ('te', 'NN'),\n",
       " ('lo', 'NN'),\n",
       " ('han', 'NN'),\n",
       " ('dicho', 'NN'),\n",
       " ('hoy', 'NN'),\n",
       " ('tu', 'NN'),\n",
       " ('eres', 'VBZ'),\n",
       " ('fuerte', 'JJ'),\n",
       " ('bonita', 'NN'),\n",
       " ('te', 'NN'),\n",
       " ('amo', 'NN'),\n",
       " ('üåπ', 'NNP'),\n",
       " ('wicked', 'VBD'),\n",
       " ('gel', 'JJ'),\n",
       " ('liner', 'NN'),\n",
       " ('coupon', 'NN'),\n",
       " ('code', 'NN'),\n",
       " ('birdy', 'IN'),\n",
       " ('hydrating', 'VBG'),\n",
       " ('spray', 'NN'),\n",
       " ('code', 'NN'),\n",
       " ('birdy', 'NN'),\n",
       " ('pearl', 'NN'),\n",
       " ('radiance', 'NN'),\n",
       " ('primer', 'NN'),\n",
       " ('foundation', 'NN'),\n",
       " ('almond', 'NN'),\n",
       " ('shape', 'NN'),\n",
       " ('tape', 'NN'),\n",
       " ('contour', 'VBP'),\n",
       " ('concealer', 'NN'),\n",
       " ('hoola', 'NN'),\n",
       " ('contour', 'NN'),\n",
       " ('stick', 'NN'),\n",
       " ('bronzer', 'NN'),\n",
       " ('powder', 'NN'),\n",
       " ('translucent', 'NN'),\n",
       " ('powder', 'NN'),\n",
       " ('rose', 'VBD'),\n",
       " ('gold', 'JJ'),\n",
       " ('highlight', 'NN'),\n",
       " ('code', 'NN'),\n",
       " ('birdy', 'IN'),\n",
       " ('whirl', 'NN'),\n",
       " ('lip', 'NN'),\n",
       " ('liner', 'NN'),\n",
       " ('nude', 'JJ'),\n",
       " ('potion', 'NN'),\n",
       " ('birdy', 'NN')]"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "regroupe_var = ' '.join(TextCleanPonctuationWord)\n",
    "\n",
    "result = TextBlob(regroupe_var)\n",
    "result.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to remove emoji.\n",
    "def del_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "                           \n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def preprocessing(singleText):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_punctuation = [':', '(', ')', '/', '|', ',', ']', ';',\n",
    "                    '.', '*', '#', '\"', '&', '~', '``',\n",
    "                    '-', '_', '\\\\', '@','?','!','\\'', '[', '<', '>', '¬£', '$', '‚Äù', \"\\u2063\", \"‚Ä¢\"]\n",
    "\n",
    "    stoplist = stopwords.words('english')\n",
    "\n",
    "    singleText = del_emoji(singleText)\n",
    "\n",
    "    LowerSingleText = singleText.lower()\n",
    "    tokenizeSingletext = word_tokenize(LowerSingleText)\n",
    "    lemmatizeSingleText = list(map(lemmatizer.lemmatize, tokenizeSingletext))\n",
    "    \n",
    "    TextCleanPonctuation = [word for word in lemmatizeSingleText if word not in stop_punctuation and word not in stoplist]\n",
    "\n",
    "    return TextCleanPonctuation\n",
    "\n",
    "def clean_text(text):\n",
    "    text_preprocessed = preprocessing(text)\n",
    "    \n",
    "    #clean_mail = [word for word in text_preprocessed if word not in stop_punctuation and not word in stoplist]\n",
    "    return ' '.join(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"skeeterbytes wrote bassam guy wrote n't anything longer 60mm except $ 99 plastic fantastic '' 40-150. 've never really tried avian photography would like get decent shot unlike opportunity arises used c-af+tr retrospect since turkey lawyer refused fly despite plea would s-af done better mf peaking magnify exposed lawyer dressed dark suit bright cloudy sky meteorologist say smoke remnant ca northern va wa +2 +2.5 ev much encouraged chroma 'm great judging distance would say wa 35+ meter away pretty intense purple fringing lightroom ha effective one-click remover 'm sure software ha hard control know panasonic 7-14 4 never use c-af+tr preferring standard c-af s-af instance s-af fine attorney n't going anywhere pay bill get s-af+magnify allow tweak focus plus want stop lens bit sharpen except 7-14 nothing else f2.8 5.6 seems stopped 'll watch tried magnify wa shaky long fl 'll try lower scale factor also raise shutter speed freeze flapping 're iso200 's good lens within realm 40-150 pro league better 10x price birding test petapixel fstoppers rated e-m5 iii pretty well c-af+tr n't use often location 5 minute walk home perhaps 'll try keep experimenting rick thanks helpful reply\""
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "result = clean_text(df_train[\"text\"].iloc[0])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On applique cela pour toute la base de donn√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        skeeterbytes wrote bassam guy wrote n't anythi...\n",
       "1        refueling long week ‚Äô meant drink prefer match...\n",
       "2        case one ha told today strong beautiful love p...\n",
       "3        forget get sunshine safely head link bio see s...\n",
       "4        abstract background human dramatically changed...\n",
       "                               ...                        \n",
       "10567    day 273 outifit thor gold foil back bling eter...\n",
       "10568    order study various trend pattern prevailing c...\n",
       "10569    brand ha yet registered influenster work brand...\n",
       "10570    regime get rid acne scar get way smoother heal...\n",
       "10571    's true used work caddie trump national nj don...\n",
       "Name: clean_content, Length: 10572, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "df_train[\"clean_content\"] = df_train.text.apply(clean_text)\n",
    "df_train[\"clean_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        skeeterbytes wrote bassam guy wrote n't anythi...\n",
       "1        refueling long week ‚Äô meant drink prefer match...\n",
       "2        case one ha told today strong beautiful love p...\n",
       "3        forget get sunshine safely head link bio see s...\n",
       "4        abstract background human dramatically changed...\n",
       "                               ...                        \n",
       "10567    day 273 outifit thor gold foil back bling eter...\n",
       "10568    order study various trend pattern prevailing c...\n",
       "10569    brand ha yet registered influenster work brand...\n",
       "10570    regime get rid acne scar get way smoother heal...\n",
       "10571    's true used work caddie trump national nj don...\n",
       "Name: clean_content, Length: 10572, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "df_train[\"clean_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x266382c33d0>"
      ],
      "text/html": "<style  type=\"text/css\" >\n#T_de106_row0_col1{\n            background-color:  #08306b;\n            color:  #f1f1f1;\n        }#T_de106_row1_col1{\n            background-color:  #d2e3f3;\n            color:  #000000;\n        }#T_de106_row2_col1{\n            background-color:  #deebf7;\n            color:  #000000;\n        }#T_de106_row3_col1,#T_de106_row4_col1,#T_de106_row5_col1,#T_de106_row6_col1,#T_de106_row7_col1,#T_de106_row8_col1{\n            background-color:  #eaf3fb;\n            color:  #000000;\n        }#T_de106_row9_col1,#T_de106_row10_col1,#T_de106_row11_col1,#T_de106_row12_col1,#T_de106_row13_col1,#T_de106_row14_col1,#T_de106_row15_col1,#T_de106_row16_col1,#T_de106_row17_col1,#T_de106_row18_col1,#T_de106_row19_col1{\n            background-color:  #f7fbff;\n            color:  #000000;\n        }</style><table id=\"T_de106_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Common_words</th>        <th class=\"col_heading level0 col1\" >count</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_de106_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_de106_row0_col0\" class=\"data row0 col0\" >website ‚Äô dashboard welcoming website ‚Äô home page visitor one way customize wordp ‚Äô got three new option adding little behind-the-scenes zing introducing powder snow nightfall sakura designed especially art director eriko kawakami whether prefer gentle monotone powder snow darker soothing color nightfall vibrant cherry-blossom-inspired sakura hope ‚Äô find look love part commitment inclusive design new palette optimized contrast increased legibility whichever color scheme choose dashboard stylish readable ‚Äô customize color scheme desktop sign wordp ‚Äô like customize.click account avatar upper right corner.select account settingsselect one option dashboard color scheme click save account setting apply change dashboard using nightfall color scheme color scheme coming want feedback color want see wordp</td>\n                        <td id=\"T_de106_row0_col1\" class=\"data row0 col1\" >18</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_de106_row1_col0\" class=\"data row1 col0\" >nfl ‚Äô 2020 trade deadline hour away ‚Äî tuesday 4 ‚Äî monday afternoon deal starting fly ‚Äô keeping past year ha made nfl ‚Äô active interesting trade deadline north</td>\n                        <td id=\"T_de106_row1_col1\" class=\"data row1 col1\" >5</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_de106_row2_col0\" class=\"data row2 col0\" >wechat whatsapp/line+8618925082788 100 % perfect quality swiss automatic movement dhl worldwide expresswesternunion payment</td>\n                        <td id=\"T_de106_row2_col1\" class=\"data row2 col1\" >4</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_de106_row3_col0\" class=\"data row3 col0\" >australia 's pacemen ready turn bouncer key wicket-taking weapon world cup expecting ball swing 2019 world cup england expected toughest yet bowler small ground flat track tipped</td>\n                        <td id=\"T_de106_row3_col1\" class=\"data row3 col1\" >3</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_de106_row4_col0\" class=\"data row4 col0\" >tension heightened donald trump 's decision suspend travel european country except united kingdom increasing case infection infection death due virus italy huge concern</td>\n                        <td id=\"T_de106_row4_col1\" class=\"data row4 col1\" >3</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_de106_row5_col0\" class=\"data row5 col0\" >chicago ‚Äî coeur mining inc. ‚Äô ‚Äú coeur ‚Äú company nyse cde senior vice president chief financial officer thomas s. whelan participate fifth annual goldman sachs leveraged finance conference thursday june 25 2020.</td>\n                        <td id=\"T_de106_row5_col1\" class=\"data row5 col1\" >3</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_de106_row6_col0\" class=\"data row6 col0\" >new zealand made three win three world cup james neesham ‚Äô maiden international five-wicket haul laid foundation comfortable win afghanistan taunton afghanistan motored along 66 without loss</td>\n                        <td id=\"T_de106_row6_col1\" class=\"data row6 col1\" >3</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n                        <td id=\"T_de106_row7_col0\" class=\"data row7 col0\" >file jan. 30 2019 photo provided sen. kevin cramer 's office tommy fisher right talk sen. kevin cramer r-n.d. lawmaker 's office washington d.c. fisher supporter president donald trump federal court hearing</td>\n                        <td id=\"T_de106_row7_col1\" class=\"data row7 col1\" >3</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n                        <td id=\"T_de106_row8_col0\" class=\"data row8 col0\" >distribution u.s. news wire service dissemination united state vancouver british columbia toronto ‚Äî auryn resource inc. tsx aug nyse american aug ‚Äú auryn ‚Äú company eastmain resource inc. tsx er ‚Äú</td>\n                        <td id=\"T_de106_row8_col1\" class=\"data row8 col1\" >3</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n                        <td id=\"T_de106_row9_col0\" class=\"data row9 col0\" >vancouver british columbia ‚Äî mogo inc. tsx mogo nasdaq mogo ‚Äú mogo ‚Äú company one canada ‚Äô leading financial technology company pleased announce previously announced amendment ‚Äú amendment</td>\n                        <td id=\"T_de106_row9_col1\" class=\"data row9 col1\" >2</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n                        <td id=\"T_de106_row10_col0\" class=\"data row10 col0\" >bpt know eat affect hair 's news people especially dealing hair loss many possible cause hair loss ‚Äî stress environment health problem ‚Äî achieving thick full</td>\n                        <td id=\"T_de106_row10_col1\" class=\"data row10 col1\" >2</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n                        <td id=\"T_de106_row11_col0\" class=\"data row11 col0\" >one plant florida sale continue growth amid covid-19 pandemic toronto ‚Äî sol global investment corp. ‚Äú sol global ‚Äú company ‚Äú cse sol otcpk solcf frankfurt 9sb today provides operational corporate update regarding</td>\n                        <td id=\"T_de106_row11_col1\" class=\"data row11 col1\" >2</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n                        <td id=\"T_de106_row12_col0\" class=\"data row12 col0\" >tel aviv israel september 5 2018 /prnewswire/ -- icl nyse icl tase icl leading global specialty mineral specialty chemical company participate credit suisse 31 st annual basic material conference ny thursday</td>\n                        <td id=\"T_de106_row12_col1\" class=\"data row12 col1\" >2</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n                        <td id=\"T_de106_row13_col0\" class=\"data row13 col0\" >source tork essity brandtork encourages company take back lunch break '' bridge gap employer employee lunch misperceptions philadelphia may 17 2018 /prnewswire/ -- today tork essity brand announces take back</td>\n                        <td id=\"T_de106_row13_col1\" class=\"data row13 col1\" >2</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n                        <td id=\"T_de106_row14_col0\" class=\"data row14 col0\" >murray energy one biggest private u.s. coal company ha become fifth coal company file bankruptcy 2019. whether people support oppose trump administration 's effort prop coal industry one point agreement</td>\n                        <td id=\"T_de106_row14_col1\" class=\"data row14 col1\" >2</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n                        <td id=\"T_de106_row15_col0\" class=\"data row15 col0\" >minneapolis officer derek chauvin seen struggling force george floyd back seat police suv newly released body camera video recorded officer tou thao chauvin thao fired along two officer involved</td>\n                        <td id=\"T_de106_row15_col1\" class=\"data row15 col1\" >2</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n                        <td id=\"T_de106_row16_col0\" class=\"data row16 col0\" >washington move reverberate congress top u.s. rocket manufacturer formally protested monday term multi-billion-dollar air force competition launching america 's future national security satellite blue origin</td>\n                        <td id=\"T_de106_row16_col1\" class=\"data row16 col1\" >2</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n                        <td id=\"T_de106_row17_col0\" class=\"data row17 col0\" >tel aviv israel july 16 2020 /prnewswire/ -- gemmacert announced today ha added new feature flagship analytical product determine composition potency cannabis throughout entire supply chain initial</td>\n                        <td id=\"T_de106_row17_col1\" class=\"data row17 col1\" >2</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n                        <td id=\"T_de106_row18_col0\" class=\"data row18 col0\" >new york april 3 2019 /prnewswire-prweb/ -- air cargo world ha announced winner 2019 air cargo excellence ace award morning live via twitter emirate airline top cargo airline world 2019 shanghai pudong airport</td>\n                        <td id=\"T_de106_row18_col1\" class=\"data row18 col1\" >2</td>\n            </tr>\n            <tr>\n                        <th id=\"T_de106_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n                        <td id=\"T_de106_row19_col0\" class=\"data row19 col0\" >san diego sept. 20 2018 /prnewswire/ -- sempra energy nyse sre today announced ha entered agreement sell u.s. non-utility operating solar asset solar battery storage development project one wind facility</td>\n                        <td id=\"T_de106_row19_col1\" class=\"data row19 col1\" >2</td>\n            </tr>\n    </tbody></table>"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "from collections import Counter\n",
    "top = Counter([item for item in df_train[\"clean_content\"]])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', '‚Äú', ' ', ' ', ' ', '‚Äù', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '‚Äô', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '‚Äô', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \"'\", ' ', ' ', '=', ' ', ' ', ' ', ' ', '+', ' ', '-', '-']\n",
      "[' ', ' ', ' ', ' ', '.', '.', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '+', ' ', ' ', ' ', ' ', ' ', ' ', '+', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '.', '.', ' ', ' ', ' ', ' ', ' ']\n",
      "['\\u200d', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '‚Äô', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '/', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', '+', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '+', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '$', ' ', '/', ' ', ' ', '$', ' ', ' ', ' ', ' ', '$', ' ', ' ', ' ', '$', ' ', ' ', ' ', ' ', '$', ' ', ' ', ' ', '$', ' ', ' ', ' ', '$', ' ', ' ', ' ', '$', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '-', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \"'\", ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '.', ' ', ' ', ' ', '‚Äú', ' ', ' ', '‚Äù', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '-', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '-', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '.', '.']\n",
      "[' ', ' ', ' ', '-', '-', ' ', \"'\", ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \"'\", ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ':', '.', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '¬£', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '¬£', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '/', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \"'\", ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \"'\", ' ', ' ', ' ', '¬£', ' ', ' ', \"'\", ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', '/', ' ', ' ', ' ', ' ', '.', ' ', ' ', ' ', '/', '/', ' ', '-', '-', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', '=', ' ', ' ', ' ', '=', ' ', ' ', ' ', '=', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '=', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', '‚Äô', ' ', ' ', ' ', ' ', ' ', ' ', 'ü•¨', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '/', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '/', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ',', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['‚Ä¢', '‚Ä¢', '‚Ä¢', ' ', ' ', ' ', ' ', ' ', '‚Ä¢', '‚Ä¢', '‚Ä¢', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '.', ' ', '%', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ',', ',', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', '.', ' ', ' ', ' ', ' ', ' ', '‚Äú', ' ', ' ', '‚Äù', ' ', '‚Äú', ' ', ' ', '‚Äù', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '.', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ']\n",
      "[\"'\", ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '/', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '‚Äú', ' ', ' ', '‚Äù', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', '‚Äô', ' ', ' ', ' ', ' ', ' ', ' ', \"'\", ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '+', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', '\\u2063', ' ', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', ' ', ' ', ' ', '\\u200d', ' ', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', '‚Äî', ' ', ' ', '\\u2063', ' ', '\\u2063', ' ', ' ', ' ', ' ', ' ', '\\u2063', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\u2063', ' ', ' ', ' ', ' ', ' ', '\\u2063', ' ', ' ', ' ', '\\u2063', ' ', ' ', ' ', '\\u2063', ' ', ' ', ' ', '\\u2063']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '-', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '-', '¬Æ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', 'ü§î', 'ü§≠', 'ü§£', ' ', ' ', ' ', ' ', '‚Äô', ' ', ' ', ' ', '-', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '¬Æ', ' ', ' ', ' ', ' ', '-', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', '/', '+', ' ', ' ', '%', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ']\n",
      "[' ', '.', ' ', ' ', '+', '.', ' ', '%', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '-', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "['‚Äú', ' ', ' ', ' ', '‚Äù', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', \"'\", ' ', ' ', '.', ' ', ' ', ' ', ' ', ' ', ' ', '.', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '.', ' ', ' ', ' ', '.', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '.', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \"'\", ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\\\', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '\\\\', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', 'ü•∞', 'ü•∞', 'ü•∞', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \"'\", ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', \"'\", ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \"'\", ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \"'\", ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \"'\", ' ', '-', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \"'\", ' ', ',', ' ', '-', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '.', ' ', ' ', ' ', ' ', ' ', ' ', '‚Äú', ' ', ' ', ' ', ' ', ' ', ' ', '‚Äù', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[\"'\", ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '-', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '$', ' ', ',', ' ', ' ', ' ', ' ', \"'\", ' ', ' ', ' ', ' ', ' ', ' ']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "10567    None\n",
       "10568    None\n",
       "10569    None\n",
       "10570    None\n",
       "10571    None\n",
       "Name: clean_content, Length: 10572, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "import re\n",
    "def found_other_than_lettre(sentence):\n",
    "    notLettre = re.findall(\"[\\W]\", sentence)\n",
    "    print(notLettre)\n",
    "\n",
    "df_train.clean_content.apply(found_other_than_lettre)"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        skeeterbytes wrote bassam guy wrote n't anythi...\n",
       "1        refueling long week ‚Äô meant drink prefer match...\n",
       "2        case one ha told today strong beautiful love p...\n",
       "3        forget get sunshine safely head link bio see s...\n",
       "4        abstract background human dramatically changed...\n",
       "                               ...                        \n",
       "10567    day 273 outifit thor gold foil back bling eter...\n",
       "10568    order study various trend pattern prevailing c...\n",
       "10569    brand ha yet registered influenster work brand...\n",
       "10570    regime get rid acne scar get way smoother heal...\n",
       "10571    's true used work caddie trump national nj don...\n",
       "Name: clean_content, Length: 10572, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "X = df_train['clean_content']\n",
    "Y = df_train.drop(['clean_content', 'index'], axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<8457x70574 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 703500 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "pipe = make_pipeline(CountVectorizer(), TfidfTransformer())\n",
    "pipe.fit(x_train)\n",
    "feat_train = pipe.transform(x_train)\n",
    "feat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<8457x70574 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 703500 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "feat_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-29ec9c4f0ecf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be class 'SparseSeries' or 'SparseArray'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mis_multilabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'multilabel-indicator'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mis_multilabel\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    150\u001b[0m                  _is_integral_float(np.unique(y.data))))\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         return len(labels) < 3 and (y.dtype.kind in 'biu' or  # bool, int, uint\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(feat_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_test = pipe.transform(x_test)\n",
    "clf.score(feat_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualisation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "score = clf.predict_proba(feat_test)\n",
    "score\n",
    "#fpr, tpr, th = roc_curve(y_list_test, score[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "aucf = auc(fpr, tpr)\n",
    "ax.plot(fpr, tpr, label='auc=%1.5f' % aucf)\n",
    "ax.set_title('Courbe ROC - classifieur de sentiments')\n",
    "ax.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}